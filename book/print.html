<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AWS AI Practitioner Study Guide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A complete and motivating study guide for the AWS Certified AI Practitioner exam">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">AWS AI Practitioner Study Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/YOUR_ORG/YOUR_REPO" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="aws-ai-practioner-exam-prep"><a class="header" href="#aws-ai-practioner-exam-prep">AWS AI Practioner Exam Prep</a></h1>
<h1 id="welcome-to-the-aws-certified-ai-practitioner-study-guide-"><a class="header" href="#welcome-to-the-aws-certified-ai-practitioner-study-guide-">Welcome to the AWS Certified AI Practitioner Study Guide üß†‚òÅÔ∏è</a></h1>
<p>This interactive study guide is designed to help you <strong>master the concepts and services required for the AWS Certified AI Practitioner certification</strong> ‚Äî with clear explanations, practical examples, and a structured flow.</p>
<hr />
<h2 id="-what-youll-learn"><a class="header" href="#-what-youll-learn">üöÄ What You‚Äôll Learn</a></h2>
<ul>
<li>
<p>üìò <strong>AI/ML Fundamentals</strong><br />
Understand the difference between AI, ML, and DL, and how they apply to real-world use cases.</p>
</li>
<li>
<p>‚òÅÔ∏è <strong>AWS AI/ML Services</strong><br />
Dive deep into services like Amazon Bedrock, Amazon Q, SageMaker, and more.</p>
</li>
<li>
<p>üîê <strong>Security &amp; Responsible AI</strong><br />
Learn about data privacy, ethical considerations, and AWS shared responsibility.</p>
</li>
<li>
<p>üíº <strong>Real-World Applications</strong><br />
See how AI/ML is transforming industries like healthcare, finance, and retail.</p>
</li>
<li>
<p>üìù <strong>Practice Questions &amp; Exam Prep</strong><br />
Reinforce your knowledge with practice questions and a final exam checklist.</p>
</li>
</ul>
<hr />
<h2 id="-how-to-use-this-guide"><a class="header" href="#-how-to-use-this-guide">üß≠ How to Use This Guide</a></h2>
<p>Use the left-hand sidebar to navigate through the topics.<br />
Each section builds on the previous one, so we recommend studying in order ‚Äî but feel free to jump around if you're reviewing specific areas.</p>
<blockquote>
<p>‚úÖ Pro Tip: Bookmark this page and revisit often while preparing.</p>
</blockquote>
<hr />
<h2 id="-maintainer"><a class="header" href="#-maintainer">üßë‚Äçüíª Maintainer</a></h2>
<p><strong>Pratham Mehta</strong><br />
Contributor to open-source AI projects, AWS practitioner, and lifelong learner.</p>
<hr />
<p>Let‚Äôs begin your AWS AI learning journey ‚Üí üìö<br />
Navigate to the next chapter from the sidebar!</p>
<h2 id="index-of-contents"><a class="header" href="#index-of-contents">Index of Contents</a></h2>
<ol>
<li>Introduction to AWS and Cloud Computing</li>
<li>Amazon Bedrock and Generative AI</li>
<li>Prompt Engineering</li>
<li>Amazon Q - Deep Dive</li>
<li>Artificial Intelligence and Machine Learning</li>
<li>AWS Managed AI Services</li>
<li>Amazon Sagemaker - Deep Dive</li>
<li>AI Challenges and Responsibilities</li>
<li>AWS Security and More</li>
<li>Tips for the Exam</li>
</ol>
<hr />
<h1 id="introduction-to-aws-and-cloud-computing"><a class="header" href="#introduction-to-aws-and-cloud-computing">Introduction to AWS and Cloud Computing</a></h1>
<p>Here are the links to notes which were similar in preparation for AWS Cloud Computing Practioner Exam:</p>
<ol>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/traditionalc.html">Traditional IT Overview</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/cc.html">What is Cloud Computing</a></li>
<li><a href="https://github.com/Sparsha-mehta/aws-ai/blob/main/typesofCC.md">Types of Cloud Computing</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/awscc.html">AWS Cloud Overview</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/ssresponsibilitymodel.html">Shared Responsibility Model &amp; AWS Acceptable Policy</a></li>
</ol>
<hr />
<h1 id="amazon-bedrock-and-generative-ai-genai"><a class="header" href="#amazon-bedrock-and-generative-ai-genai"><a href="https://github.com/Sparsha-mehta/aws-ai/blob/main/amazonbedrock.md">Amazon Bedrock and Generative AI (GenAI)</a></a></h1>
<ol>
<li><a href="https://github.com/Sparsha-mehta/aws-ai/blob/main/amazonbedrock.md#section-1--what-is-genai">What is Generative AI?</a></li>
<li><a href="https://sparsha-mehta.github.io/aws-ai/amazonbedrock.html#section-2--amazon-bedrock---overview">Amazon Bedrock - Overview</a></li>
<li>[Amazon Bedrock - Hands On](Bedrock Hands On.pdf)</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="1-introduction-to-aws-and-cloud-computing"><a class="header" href="#1-introduction-to-aws-and-cloud-computing">1. Introduction to AWS and Cloud Computing</a></h2>
<p>Here are the links to notes which were similar in preparation for AWS Cloud Computing Practioner Exam:</p>
<ol>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/traditionalc.html">Traditional IT Overview</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/cc.html">What is Cloud Computing</a></li>
<li><a href="https://sparsha-mehta.github.io/aws-ai/typesofCC.html">Types of Cloud Computing</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/awscc.html">AWS Cloud Overview</a></li>
<li><a href="https://pratham-mehta.github.io/ccp/content/cloudcomp/ssresponsibilitymodel.html">Shared Responsibility Model &amp; AWS Acceptable Policy</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="types-of-cloud-computing"><a class="header" href="#types-of-cloud-computing">Types of Cloud Computing</a></h1>
<h3 id="1-infrastructure-as-a-service-iaas"><a class="header" href="#1-infrastructure-as-a-service-iaas">1. <strong>Infrastructure as a Service (IaaS)</strong></a></h3>
<ul>
<li>
<p>There are the building blocks for Cloud IT</p>
</li>
<li>
<p>With the IaaS, we are going to provide networking, computers, and data storage space in its raw form</p>
</li>
<li>
<p>Using this building blocks (like Legos), we will get High Level of Flexibility</p>
</li>
<li>
<p>With this, we can easily migrate from Traditional on Premises-IT to Cloud</p>
</li>
</ul>
<h3 id="2-platform-as-a-service-paas"><a class="header" href="#2-platform-as-a-service-paas">2. <strong>Platform as a Service (PaaS)</strong></a></h3>
<ul>
<li>
<p>In this, we are going to remove the need for your organization to manage the underlying infrastructure</p>
</li>
<li>
<p>You can focus on the deployment and management of your applications</p>
</li>
</ul>
<h3 id="3-software-as-a-service-saas"><a class="header" href="#3-software-as-a-service-saas">3. <strong>Software as a Service (SaaS)</strong></a></h3>
<ul>
<li>This is a completed product that is going to be run and managed by the Service Provider</li>
</ul>
<h2 id="so-if-you-want-to-compare-all-of-these-things"><a class="header" href="#so-if-you-want-to-compare-all-of-these-things">So if you want to compare all of these things:</a></h2>
<p>Let us take an example ‚Üí <strong>On Premises</strong>, you are going to manage everything. This will involve your:</p>
<ol>
<li>
<p>Applications</p>
</li>
<li>
<p>Data</p>
</li>
<li>
<p>Runtime</p>
</li>
<li>
<p>Middleware</p>
</li>
<li>
<p>OS (Operating System)</p>
</li>
<li>
<p>Virtualization</p>
</li>
<li>
<p>Servers</p>
</li>
<li>
<p>Storage</p>
</li>
<li>
<p>Networking</p>
</li>
</ol>
<h3 id="with-iaas-infrastructure-as-a-service-we-manage"><a class="header" href="#with-iaas-infrastructure-as-a-service-we-manage">With <strong>IaaS</strong> (Infrastructure as a Service), we manage:</a></h3>
<ol>
<li>
<p>Applications</p>
</li>
<li>
<p>Data</p>
</li>
<li>
<p>Runtime</p>
</li>
<li>
<p>Middleware</p>
</li>
<li>
<p>OS</p>
</li>
</ol>
<p>While AWS manages:<br />
6. Virtualization<br />
7. Servers<br />
8. Storage<br />
9. Networking</p>
<p>With the <strong>PaaS</strong> (Platform as a Service), we manage even less, so everything from the runtime to the networking is managed by AWS and the only thing we care about when we use a platform as a service is our application and our data, meaning:<br></p>
<ol>
<li>Application (we will manage this)<br></li>
<li>Data (we will manage this)<br></li>
<li>Runtime (AWS will handle it)<br></li>
<li>Middleware (AWS will handle it)<br></li>
<li>OS (AWS will handle it)<br></li>
<li>Virtualization (AWS will handle it)<br></li>
<li>Servers (AWS will handle it)<br></li>
<li>Storage (AWS will handle it)<br></li>
<li>Networking (AWS will handle it)<br></li>
</ol>
<p>See the image below for better understanding:<br>
<img src="image.png" alt="alt text" /></p>
<p>Finally if you are using Software as a service (SaaS), Everything is going to be managed by the AWS
<img src="image-1.png" alt="alt text" /></p>
<h2 id="examples-of-cloud-computing-types"><a class="header" href="#examples-of-cloud-computing-types">Examples of Cloud Computing Types</a></h2>
<p>Well with the <strong>IaaS</strong>, we can use:<br></p>
<ol>
<li>EC2 (With AWS)<br></li>
<li>GCP, Azure, Rackspace, Digital Ocean, Linode<br></li>
</ol>
<p>With <strong>PaaS</strong>, also exists on AWS, and example include:<br></p>
<ol>
<li>Elastic Beanstalk (on AWS)<br></li>
<li>Outside of AWS, the examples include:  Heroku, Google App Engine (GCP), Windows Azure (Microsoft)</li>
</ol>
<p>For <strong>SaaS</strong>, we will also have this on AWS, that represents many services:<br></p>
<ol>
<li>Rekognition for ML (AWS service)<br></li>
<li>Real world applications like Gmail (Google App), Dropbox, Zoom for Meetings</li>
</ol>
<h2 id="pricing-of-the-cloud"><a class="header" href="#pricing-of-the-cloud">Pricing of the Cloud</a></h2>
<ul>
<li>AWS has 3 pricing fundamentals. It will follow the pay-as-you-go pricing model</li>
<li>For Compute: (Since for compute, it is involved in various services)<br>
<ul>
<li>We are going to pay for exact compute time<br>
<img src="image-2.png" alt="alt text" /></li>
</ul>
</li>
<li>For Storage:<br>
<ul>
<li>We are going to pay for the exact amount of the data stored in the cloud<br>
<img src="image-3.png" alt="alt text" /></li>
</ul>
</li>
<li>For Networking:<br>
<ul>
<li>We are going to only pay when the data leaves the cloud. <br></li>
<li>Any data that goes into the cloud is <strong>Free</strong>. (This solves the expensive issue of Traditional IT)</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="amazon-bedrock-and-generative-ai"><a class="header" href="#amazon-bedrock-and-generative-ai">Amazon Bedrock and Generative AI</a></h1>
<p>In this section, we are going to talk about generative AI, and amazon bedrock (which is the main service on AWS that does generative AI). This is actually one of the main topic of the exam and one of the fastest growing AWS service.</p>
<h2 id="section-1--what-is-genai"><a class="header" href="#section-1--what-is-genai"><a href="GenAI.html">Section 1 : What is GenAI?</a></a></h2>
<h2 id="section-2--amazon-bedrock---overview"><a class="header" href="#section-2--amazon-bedrock---overview"><a href="bedrockover.html">Section 2 : Amazon Bedrock - Overview</a></a></h2>
<h2 id="section-3--foundational-model"><a class="header" href="#section-3--foundational-model"><a href="foundationalmodel.html">Section 3 : Foundational Model</a></a></h2>
<h2 id="section-4--fine-tuning-a-model"><a class="header" href="#section-4--fine-tuning-a-model">Section 4 : Fine-Tuning a Model</a></h2>
<h2 id="section-5--fm-evaluation"><a class="header" href="#section-5--fm-evaluation">Section 5 : FM Evaluation</a></h2>
<h2 id="fm-evaluation---hands-on"><a class="header" href="#fm-evaluation---hands-on">FM Evaluation - Hands On</a></h2>
<h2 id="section-6--rag--knowledge-base"><a class="header" href="#section-6--rag--knowledge-base">Section 6 : RAG &amp; Knowledge Base</a></h2>
<h2 id="rag--knowledege-base---hands-on"><a class="header" href="#rag--knowledege-base---hands-on">RAG &amp; Knowledege Base - Hands On</a></h2>
<h2 id="section-7--more-genai-concepts"><a class="header" href="#section-7--more-genai-concepts">Section 7 : More GenAI Concepts</a></h2>
<h2 id="section-8--guardrails"><a class="header" href="#section-8--guardrails">Section 8 : GuardRails</a></h2>
<h2 id="guardrails---hands-on"><a class="header" href="#guardrails---hands-on">GuardRails - Hands On</a></h2>
<h2 id="section-9--agents"><a class="header" href="#section-9--agents">Section 9 : Agents</a></h2>
<h2 id="section-10--cloudwatch-integration"><a class="header" href="#section-10--cloudwatch-integration">Section 10 : CloudWatch Integration</a></h2>
<h2 id="cloudwatch-integration---hands-on"><a class="header" href="#cloudwatch-integration---hands-on">CloudWatch Integration - Hands On</a></h2>
<h2 id="section-11--pricing"><a class="header" href="#section-11--pricing">Section 11 : Pricing</a></h2>
<h2 id="section-12--ai-stylist"><a class="header" href="#section-12--ai-stylist">Section 12 : AI Stylist</a></h2>
<h2 id="quiz"><a class="header" href="#quiz">Quiz</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-genai"><a class="header" href="#what-is-genai">What is GenAI?</a></h1>
<h2 id="introduction-to-generative-ai"><a class="header" href="#introduction-to-generative-ai">Introduction to Generative AI</a></h2>
<p>Now that we are about to dive into <strong>Amazon Bedrock</strong>, which is a service for Generative AI (Gen AI) on AWS, let‚Äôs take a step back and understand <strong>what Gen AI actually is</strong>.</p>
<p>Generative AI is a <strong>subset of deep learning</strong>, which is itself a <strong>subset of machine learning</strong>, and in turn, a subset of <strong>artificial intelligence (AI)</strong>.</p>
<p><img src="image-16.png" alt="alt text" /></p>
<h2 id="what-is-generative-ai"><a class="header" href="#what-is-generative-ai">What is Generative AI?</a></h2>
<ul>
<li>
<p>Gen AI is used to <strong>generate new data</strong> that resembles the data it was trained on.</p>
</li>
<li>
<p>It can be trained on <strong>various types of data</strong>:</p>
<ul>
<li>Text</li>
<li>Images</li>
<li>Audio</li>
<li>Code</li>
<li>Video</li>
<li>And more</li>
</ul>
</li>
</ul>
<p><strong>Example</strong>:
If we train a Gen AI model on a lot of dog images and also on hand-drawn cartoons, then ask it to generate a ‚Äúcartoon dog,‚Äù it will combine the two together and create a dog that looks like a cartoon. That is the power of Generative AI</p>
<ul>
<li>This is the <strong>power of Gen AI</strong>: it <strong>combines its knowledge into new, and unique ways</strong>.</li>
</ul>
<p><img src="image-4.png" alt="GenAI Model Image" /></p>
<ul>
<li>We are going to start with lots of unlabelled data (we will look later in the course, what it means by unlabelled data).</li>
<li>We are going to train Foundational Model.</li>
<li>Foundational Model (FM) are very broad, they are very big and very wide.</li>
<li>FM can easily adapt to different kind of general tasks.</li>
<li>A good foundational model can do:
<ul>
<li>Text Generation</li>
<li>Text Summarization</li>
<li>Information Extraction</li>
<li>Image Generation</li>
<li>Can become a <strong>Chatbot</strong></li>
<li>Question Answering</li>
</ul>
</li>
<li>In general, we feed a lot of data into a foundational model, which has a option to do a lot of different tasks.
<img src="image-14.png" alt="alt text" />
Now let's talk about Foundational Models</li>
</ul>
<h2 id="foundation-models"><a class="header" href="#foundation-models">Foundation Models</a></h2>
<ul>
<li>
<p>In order to generate data, as we said, we need to have Foundational Model.</p>
</li>
<li>
<p>FM are trained on a wide variety of inputs.</p>
</li>
<li>
<p>Now to train foundational models:
<img src="image-13.png" alt="alt text" />
<strong>Training foundation models:</strong></p>
</li>
<li>
<p>It requires <strong>millions of dollars</strong>, massive computing resources, and a lot of data.</p>
</li>
<li>
<p>It is typically built by <strong>large companies</strong> like:</p>
<ul>
<li><strong>OpenAI</strong> ‚Äì (e.g., GPT-4o)</li>
<li><strong>Meta</strong></li>
<li><strong>Amazon</strong></li>
<li><strong>Google</strong></li>
<li><strong>Anthropic</strong></li>
</ul>
</li>
</ul>
<h2 id="open-source-vs-commercial-models"><a class="header" href="#open-source-vs-commercial-models">Open Source vs Commercial Models</a></h2>
<ul>
<li>
<p>Some foundation models are <strong>open source</strong> (free to use):</p>
<ul>
<li>Example: Meta‚Äôs open-source efforts, Google‚Äôs BERT</li>
</ul>
</li>
<li>
<p>Others are <strong>commercially licensed</strong>:</p>
<ul>
<li>Example: OpenAI‚Äôs GPT models, Anthropic models</li>
</ul>
</li>
</ul>
<p>We will also see how to access these models on AWS as well.</p>
<h2 id="large-language-models-llms"><a class="header" href="#large-language-models-llms">Large Language Models (LLMs)</a></h2>
<ul>
<li>LLMs are a <strong>type of AI</strong> that rely on foundation models and are designed to <strong>generate coherent human-like text</strong>.</li>
<li>Example: <strong>ChatGPT</strong> using <strong>GPT-4</strong></li>
<li>These LLMs are usually very Big Models:
<ul>
<li>They are trained on large corpus of text data</li>
<li>They are computionally heavy and use <strong>Billions of parameters</strong></li>
<li>They are trained on Books, articles, websites, other textual data</li>
</ul>
</li>
<li>They can perform wide range of language related tasks, which involves:
<ul>
<li>Translation, Summarization</li>
<li>Question Answering</li>
<li>Content Creation</li>
</ul>
</li>
<li>How does it work when we interact with the LLM</li>
</ul>
<p><strong>Interaction:</strong></p>
<ul>
<li>We interact with the LLM by giving a prompt, for example : <em>"What is AWS"</em></li>
</ul>
<blockquote>
<p>Note that, we will have dedicated section to understand about how to create prompt</p>
</blockquote>
<ul>
<li>Then the model is going to leverage all the existing content that it has learned from to generate new content.</li>
<li>The generated text is <strong>Non Deterministic</strong>,that means that for every user that is using the same prompt, will get different generated text. (it won't be the same answer every time, see the image below)</li>
</ul>
<p><img src="image-5.png" alt="alt text" /></p>
<h2 id="non-determinism-in-llms"><a class="header" href="#non-determinism-in-llms">Non-Determinism in LLMs</a></h2>
<p>So let's understand why though it is non-deterministic. Let's take an example:</p>
<h3 id="example-sentence"><a class="header" href="#example-sentence">Example sentence:</a></h3>
<p><em>‚ÄúAfter the rain, the streets were‚Ä¶‚Äù</em></p>
<p>When an LLM sees this prompt, it calculates a <strong>list of potential next words</strong> along with <strong>probabilities</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Word</th><th>Probability</th></tr></thead><tbody>
<tr><td>wet</td><td>0.40</td></tr>
<tr><td>flooded</td><td>0.25</td></tr>
<tr><td>slippery</td><td>0.15</td></tr>
<tr><td>empty</td><td>0.05</td></tr>
<tr><td>muddy</td><td>0.05</td></tr>
<tr><td>clean</td><td>0.04</td></tr>
<tr><td>blocked</td><td>0.03</td></tr>
<tr><td>...</td><td>...</td></tr>
</tbody></table>
</div>
<ul>
<li>
<p>These are <strong>statistically likely next words</strong>, based on what the model has seen during training.</p>
</li>
<li>
<p>Then, an <strong>algorithm picks</strong> one of the words ‚Äî maybe ‚Äúflooded‚Äù.</p>
</li>
</ul>
<p>So the model outputs:</p>
<blockquote>
<p><em>‚ÄúAfter the rain, the streets were flooded.‚Äù</em></p>
</blockquote>
<p>This selection is based on <strong>random sampling with probabilities</strong>, not fixed logic.
<img src="image-6.png" alt="alt text" /></p>
<p>The process <strong>repeats for every next word</strong>.</p>
<p>Given:</p>
<blockquote>
<p><em>‚ÄúAfter the rain, the streets were flooded...‚Äù</em></p>
</blockquote>
<p>The next word could be:</p>
<div class="table-wrapper"><table><thead><tr><th>Word</th><th>Probability</th></tr></thead><tbody>
<tr><td>and</td><td>0.40</td></tr>
<tr><td>with</td><td>0.25</td></tr>
<tr><td>from</td><td>0.15</td></tr>
<tr><td>because</td><td>0.05</td></tr>
<tr><td>until</td><td>0.05</td></tr>
<tr><td><code>.</code></td><td>0.04</td></tr>
<tr><td>...</td><td>...</td></tr>
</tbody></table>
</div>
<ul>
<li>All of these again, have associated probabilites, then the next word is going to be selected based on these probabilities.</li>
<li>This is why when you ask the AI twice the same prompt, you may not get the same answers</li>
<li>Because the sentence is determined with the statistical methods and not with the deterministic methods.
<img src="image-7.png" alt="alt text" /></li>
</ul>
<h2 id="generative-ai-for-images"><a class="header" href="#generative-ai-for-images">Generative AI for Images</a></h2>
<p>Let‚Äôs now understand how <strong>Generative AI works with images</strong>.</p>
<p>Gen AI is not limited to text. It can also <strong>generate images</strong> based on prompts or existing images, and it can even <strong>understand images</strong> to generate text descriptions.</p>
<h3 id="types-of-image-based-gen-ai-tasks"><a class="header" href="#types-of-image-based-gen-ai-tasks">Types of Image-Based Gen AI Tasks</a></h3>
<h4 id="1-text-to-image-generation"><a class="header" href="#1-text-to-image-generation">1. <strong>Text-to-Image Generation</strong></a></h4>
<p><img src="image-8.png" alt="alt text" /></p>
<ul>
<li>
<p>You give a prompt like:</p>
<blockquote>
<p><em>‚ÄúGenerate a blue sky with white clouds and the word ‚ÄòHello‚Äô written in the sky.‚Äù</em></p>
</blockquote>
</li>
<li>
<p>The Gen AI model uses that input to <strong>create a new image</strong> that visually matches the description.</p>
</li>
<li>
<p>The image is generated <strong>from scratch</strong>, not copied from a dataset.</p>
</li>
</ul>
<h4 id="2-image-to-image-translation"><a class="header" href="#2-image-to-image-translation">2. <strong>Image-to-Image Translation</strong></a></h4>
<p><img src="image-9.png" alt="alt text" /></p>
<ul>
<li>
<p>You provide an <strong>input image</strong> and a <strong>style transformation instruction</strong>.</p>
</li>
<li>
<p>Example:</p>
<ul>
<li>
<p>Input: A photo of someone playing the piano</p>
</li>
<li>
<p>Prompt: <em>‚ÄúTransform this into Japanese anime style.‚Äù</em></p>
</li>
</ul>
</li>
<li>
<p>Output: A version of the same image that now looks like it was drawn in <strong>manga/anime style</strong>.</p>
</li>
</ul>
<h4 id="3-image-to-text-visual-question-answering"><a class="header" href="#3-image-to-text-visual-question-answering">3. <strong>Image-to-Text (Visual Question Answering)</strong></a></h4>
<p><img src="image-10.png" alt="alt text" /></p>
<ul>
<li>
<p>You give a picture and ask a question about it.</p>
</li>
<li>
<p>Example:</p>
<ul>
<li>
<p>Image: One apple and one orange</p>
</li>
<li>
<p>Prompt: <em>‚ÄúHow many apples do you see in the picture?‚Äù</em></p>
</li>
</ul>
</li>
<li>
<p>Output:</p>
<blockquote>
<p><em>‚ÄúThe picture shows one apple and the other fruit is an orange.‚Äù</em></p>
</blockquote>
</li>
<li>
<p>The model is capable of <strong>understanding the contents of the image</strong> and generating relevant, human-like answers.</p>
</li>
</ul>
<h2 id="diffusion-models-behind-the-scenes"><a class="header" href="#diffusion-models-behind-the-scenes">Diffusion Models (Behind the Scenes)</a></h2>
<p>One popular technique behind image generation is called a <strong>diffusion model</strong>. A well-known example is <strong>Stable Diffusion</strong>, which is based on this method.</p>
<p>Let‚Äôs break this down into two key processes:</p>
<h3 id="1-forward-diffusion-training-phase"><a class="header" href="#1-forward-diffusion-training-phase"><strong>1. Forward Diffusion (Training Phase)</strong></a></h3>
<ul>
<li>
<p>We start with a <strong>clear image</strong>, like a picture of a cat.</p>
</li>
<li>
<p>Then, we <strong>gradually add noise</strong> to the image, step by step:</p>
<ul>
<li>Slight noise ‚Üí more noise ‚Üí until the image becomes <strong>pure noise</strong>.</li>
</ul>
</li>
</ul>
<p><img src="image-11.png" alt="alt text" /></p>
<ul>
<li>
<p>Eventually, the image becomes <strong>completely unrecognizable</strong>.</p>
</li>
<li>
<p>This teaches the model <strong>how images degrade into noise</strong>.</p>
</li>
</ul>
<p>This is called the <strong>forward diffusion process</strong>.</p>
<p>This process is done for a lot of pictures. Once the algorithm is trained to take images and create noise out of it,  then we do the opposite that is  <strong>Reverse Diffusion</strong></p>
<h3 id="2-reverse-diffusion-image-generation-phase"><a class="header" href="#2-reverse-diffusion-image-generation-phase"><strong>2. Reverse Diffusion (Image Generation Phase)</strong></a></h3>
<ul>
<li>
<p>Now we want to <strong>generate a new image</strong> from scratch.</p>
</li>
<li>
<p>The model starts with <strong>random noise</strong> and a <strong>text prompt</strong> like:</p>
<blockquote>
<p><em>‚ÄúA cat with a computer‚Äù</em></p>
</blockquote>
</li>
<li>
<p>The model then works <strong>in reverse</strong>:</p>
<ul>
<li>
<p>It <strong>removes the noise step-by-step</strong>, each time refining the image.</p>
</li>
<li>
<p>Over multiple steps, the image <strong>gradually becomes clear</strong>.</p>
</li>
<li>
<p>Final output: A unique image of <strong>a cat with a computer</strong>.</p>
</li>
</ul>
</li>
</ul>
<p><img src="image-12.png" alt="alt text" /></p>
<blockquote>
<p>This image is <strong>new</strong> ‚Äî not taken from training data ‚Äî but created using the knowledge learned from how <strong>real images look and how noise distorts them</strong>.</p>
</blockquote>
<h2 id="summary-of-key-concepts"><a class="header" href="#summary-of-key-concepts">Summary of Key Concepts</a></h2>
<ul>
<li><strong>Gen AI</strong> creates new content (text, images, audio) from training data.</li>
<li><strong>Foundation models</strong> are trained on vast, diverse data to support multiple tasks.</li>
<li><strong>LLMs</strong> generate human-like text and are based on probability, not fixed rules.</li>
<li><strong>Non-deterministic output</strong> ensures variability in responses.</li>
<li><strong>Diffusion models</strong> generate images by reversing a noise process.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="amazon-bedrock---overview"><a class="header" href="#amazon-bedrock---overview">Amazon Bedrock - Overview</a></h1>
<h2 id="introduction-to-amazon-bedrock"><a class="header" href="#introduction-to-amazon-bedrock">Introduction to Amazon Bedrock</a></h2>
<p>Now that we've learned about Generative AI and foundation models, it's time to talk about <strong>Amazon Bedrock</strong>, the <strong>main service on AWS used to build generative AI applications</strong>.</p>
<p>Amazon Bedrock is a <strong>fully managed service</strong>, which means you don‚Äôt have to worry about managing the underlying infrastructure. It provides a simple way to access and interact with multiple foundation models through a unified interface.</p>
<h2 id="key-features-of-amazon-bedrock"><a class="header" href="#key-features-of-amazon-bedrock">Key Features of Amazon Bedrock</a></h2>
<ul>
<li>
<p><strong>Fully managed service</strong>:</p>
<ul>
<li>No need to manage infrastructure</li>
<li>AWS handles everything behind the scenes</li>
</ul>
</li>
<li>
<p><strong>Data privacy</strong>:</p>
<ul>
<li>Your data stays <strong>within your AWS account</strong></li>
<li>It is <strong>not used to retrain</strong> the underlying foundation models</li>
</ul>
</li>
<li>
<p><strong>Pay-per-use pricing model</strong>:</p>
<ul>
<li>You only pay for what you use</li>
<li>Pricing details will be discussed later</li>
</ul>
</li>
<li>
<p><strong>Unified API</strong>:</p>
<ul>
<li>One standardized method to interact with all foundation models</li>
<li>Simplifies application development</li>
</ul>
</li>
<li>
<p><strong>Multiple foundation models available</strong>:</p>
<ul>
<li>Easily choose and configure models from different providers</li>
</ul>
</li>
<li>
<p><strong>Advanced features</strong> included:</p>
<ul>
<li><strong>RAG</strong> (Retrieval Augmented Generation)</li>
<li><strong>LLM Agents</strong></li>
<li><strong>Security, privacy, governance, and responsible AI</strong> built-in in Amazon Bedrock</li>
</ul>
</li>
</ul>
<h2 id="what-type-of-foundation-models-are-available-in-bedrock"><a class="header" href="#what-type-of-foundation-models-are-available-in-bedrock">What type of Foundation Models are Available in Bedrock</a></h2>
<p>Amazon Bedrock offers access to models from various top-tier AI providers:</p>
<ul>
<li><strong>AI21 Labs</strong></li>
<li><strong>Cohere</strong></li>
<li><strong>Stability.ai</strong></li>
<li><strong>Amazon</strong></li>
<li><strong>Anthropic</strong></li>
<li><strong>Meta</strong></li>
<li><strong>Mistral AI</strong></li>
</ul>
<blockquote>
<p>üìå More providers and models will continue to be added over time.</p>
</blockquote>
<h2 id="how-bedrock-handles-models"><a class="header" href="#how-bedrock-handles-models">How Bedrock Handles Models</a></h2>
<ul>
<li>
<p>When you use a foundation model:</p>
<ul>
<li><strong>Bedrock creates a copy</strong> of the model instance for <strong>your exclusive use</strong></li>
<li>This ensures data isolation and privacy</li>
</ul>
</li>
<li>
<p>In some cases, you can <strong>fine-tune the model with your own data</strong> to better align it with your specific needs</p>
</li>
<li>
<p>Again, <strong>none of your data is sent back</strong> to the original model providers</p>
</li>
</ul>
<hr />
<h2 id="bedrock-architecture-overview"><a class="header" href="#bedrock-architecture-overview">Bedrock Architecture Overview</a></h2>
<p>Let‚Äôs visualize how Bedrock works, using a simplified diagram explained during the lecture:</p>
<h3 id="core-flow"><a class="header" href="#core-flow">Core Flow:</a></h3>
<p><img src="image-15.png" alt="alt text" /></p>
<ol>
<li>
<p><strong>Users interact with an interactive playground</strong></p>
<ul>
<li>
<p>Users <strong>select the model</strong> to use</p>
</li>
<li>
<p>Input a question like:</p>
<blockquote>
<p><em>‚ÄúWhat is the most popular dish in Italy?‚Äù</em></p>
</blockquote>
</li>
<li>
<p>Model responds with an answer, for example:</p>
<blockquote>
<p><em>‚ÄúPizza and pasta‚Äù</em></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>We can have <strong>Knowledge Bases / RAG</strong> (Retrieval Augmented Generation)</p>
<ul>
<li>This allows fetching <strong>external data</strong> to provide <strong>more accurate and relevant answers</strong> (will be covered in detail in later sections)</li>
</ul>
</li>
<li>
<p><strong>Model Fine-Tuning</strong></p>
<ul>
<li>You can upload and apply your <strong>own data</strong> to personalize the foundation model</li>
<li>All fine-tuning stays <strong>within your AWS account</strong></li>
</ul>
</li>
<li>
<p><strong>Unified API Access</strong></p>
<ul>
<li>All apps communicate with Bedrock using a <strong>single API format</strong></li>
<li>Bedrock manages model selection and orchestration behind the scenes</li>
</ul>
</li>
</ol>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<ul>
<li>Amazon Bedrock makes it easy to <strong>build, test, and deploy</strong> Gen AI applications using various foundation models.</li>
<li>It gives you <strong>data privacy</strong>, <strong>scalability</strong>, <strong>fine-tuning</strong>, and a <strong>unified developer experience</strong>.</li>
<li>In the next lecture, we‚Äôll explore <strong>hands-on practice</strong> with Bedrock‚Äôs <strong>interactive playground</strong>.</li>
</ul>
<h2 id="amazon-bedrock---hands-on"><a class="header" href="#amazon-bedrock---hands-on"><a href="https://github.com/Sparsha-mehta/aws-ai/blob/main/Bedrock%20Hands%20On.pdf">Amazon Bedrock - Hands On</a></a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="foundational-model"><a class="header" href="#foundational-model">Foundational Model</a></h1>
<p>This section covers the key considerations and trade-offs involved in selecting a <strong>base foundation model</strong> within Amazon Bedrock. The choice of model depends on several factors including:</p>
<ul>
<li>
<p>performance,</p>
</li>
<li>
<p>token capacity,</p>
</li>
<li>
<p>language support,</p>
</li>
<li>
<p>modality,</p>
</li>
<li>
<p>cost,</p>
</li>
<li>
<p>customization options, and</p>
</li>
<li>
<p>inference speed.</p>
</li>
</ul>
<p>There is no single best option, as each model brings unique strengths and constraints. Therefore, experimentation and alignment with business needs are crucial.</p>
<h2 id="factors-to-consider-when-selecting-a-model"><a class="header" href="#factors-to-consider-when-selecting-a-model">Factors to Consider When Selecting a Model</a></h2>
<p>Several key parameters influence the choice of a foundation model:</p>
<ul>
<li>
<p>The required level of <strong>performance</strong> and <strong>capability</strong></p>
</li>
<li>
<p>The <strong>maximum token context window</strong>, which determines how much input data the model can process</p>
</li>
<li>
<p>Whether the model supports <strong>multimodal input and output</strong>, such as text, image, audio, or video</p>
</li>
<li>
<p>The <strong>cost per 1,000 tokens</strong> or per request</p>
</li>
<li>
<p>The ability to perform <strong>fine-tuning</strong> with your own data</p>
</li>
<li>
<p>The <strong>licensing agreements</strong>, which may vary across models</p>
</li>
<li>
<p>The expected <strong>latency</strong> during inference</p>
</li>
</ul>
<p>Some models are optimized for cost-effectiveness while others are designed to deliver high-accuracy outputs. Multimodal capabilities, in particular, are important for applications involving diverse media formats.</p>
<h2 id="amazon-titan-and-its-role-in-the-aws-ecosystem-v-imp-for-exam"><a class="header" href="#amazon-titan-and-its-role-in-the-aws-ecosystem-v-imp-for-exam">Amazon Titan and Its Role in the AWS Ecosystem (V Imp for Exam)</a></h2>
<p>Since this course focuses on AWS, special attention is given to <strong>Amazon Titan</strong>, which is Amazon‚Äôs High-performing foundation model suite.</p>
<p>Titan supports <strong>text and image generation</strong>, as well as <strong>multimodal capabilities</strong>.</p>
<p>The model can be <strong>fine-tuned</strong> with custom datasets using a <strong>unified API</strong> within Amazon Bedrock.</p>
<p>Smaller versions of Titan may be more <strong>cost-effective</strong> but will likely have <strong>reduced knowledge coverage</strong> compared to larger, more capable models. Deciding which version to use is a balance between <strong>cost and quality</strong>.</p>
<h2 id="comparing-four-popular-foundation-models"><a class="header" href="#comparing-four-popular-foundation-models">Comparing Four Popular Foundation Models</a></h2>
<p>The following comparison covers four commonly available models on Amazon Bedrock:</p>
<div class="table-wrapper"><table><thead><tr><th>Model</th><th>Max Tokens</th><th>Features</th><th>Use Cases</th><th>Pricing (per 1K tokens)</th></tr></thead><tbody>
<tr><td><strong>Amazon Titan (Text Express)</strong></td><td>8K</td><td>High-performance text model, supports 100+ languages</td><td>Content creation, classification, education</td><td>Input: $0.0008, Output: $0.0016</td></tr>
<tr><td><strong>Llama 2 (70B-chat)</strong></td><td>4K</td><td>Suited for large-scale tasks and English dialogue</td><td>Text generation, customer service</td><td>Input: $0.0019, Output: $0.0025</td></tr>
<tr><td><strong>Claude 2.1</strong></td><td>200K</td><td>High-capacity text generation, multilingual</td><td>Analysis, forecasting, document comparison</td><td>Input: $0.008, Output: $0.024</td></tr>
<tr><td><strong>Stable Diffusion (SDXL 1.0)</strong></td><td>77 Tokens/Prompt</td><td>Image generation only</td><td>Image creation for advertising, media...</td><td>$0.04‚Äì$0.08 per image</td></tr>
</tbody></table>
</div>
<h2 id="observations-based-on-the-comparison"><a class="header" href="#observations-based-on-the-comparison">Observations Based on the Comparison</a></h2>
<ul>
<li>
<p><strong>Claude 2.1</strong> offers the <strong>largest context window</strong> (200K tokens), making it suitable for processing large codebases, books, or documents. This is critical in use cases that require deep memory of long inputs.</p>
</li>
<li>
<p><strong>Amazon Titan</strong> is significantly <strong>cheaper</strong> than both Llama 2 and Claude, while still supporting multilingual capabilities.</p>
</li>
<li>
<p><strong>Llama 2</strong> provides strong performance for conversational and English-based tasks but has a smaller context window and slightly higher cost than Titan.</p>
</li>
<li>
<p><strong>Stable Diffusion</strong> is purely for image-related generation and accepts shorter prompts. Its cost is per image rather than per token, and it supports features like object removal, background replacement, and visual modification.</p>
</li>
</ul>
<h2 id="final-thoughts-on-model-selection"><a class="header" href="#final-thoughts-on-model-selection">Final Thoughts on Model Selection</a></h2>
<p>While all these models are converging toward similar capabilities, the real decision comes down to <strong>testing</strong> each one for your specific needs:</p>
<ul>
<li>
<p><strong>Claude</strong> may be preferred for heavy document analysis and large prompt sizes.</p>
</li>
<li>
<p><strong>Titan</strong> offers a strong balance between performance, cost, and multilingual support.</p>
</li>
<li>
<p><strong>Llama 2</strong> is ideal for scalable dialogue and customer-facing tasks.</p>
</li>
<li>
<p><strong>Stable Diffusion</strong> is the go-to for image and creative generation needs.</p>
</li>
</ul>
<p>Pricing is a key differentiator. <strong>Claude is the most expensive</strong>, while <strong>Amazon Titan offers the lowest cost</strong> per token. Rapid cost accumulation is possible with large-scale inference or continuous image generation, so monitoring usage is essential.</p>
<h2 id="foundational-model---hands-on"><a class="header" href="#foundational-model---hands-on"><a href="https://github.com/Sparsha-mehta/aws-ai/blob/main/Foundation%20Models%20Hands%20On.pdf">Foundational Model - Hands On</a></a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-engineering"><a class="header" href="#prompt-engineering">Prompt Engineering</a></h1>
<p>In this section, we are going to study about Prompt Engineering. It is important because:</p>
<ol>
<li>It is asked in the exam</li>
<li>The skills you will learn, can be used for any LLMs out there</li>
</ol>
<p>Mastering Prompt Engineering, will help you keep ahead in AI race. I hope you are excited, let's dive in</p>
<h2 id="index"><a class="header" href="#index">Index:</a></h2>
<ol>
<li><a href="promptengg.html">What is Prompt Engineering?</a></li>
<li><a href="promptengg-handson.html">Prompt Engineering - Hands On</a></li>
<li><a href="promptperf.html">Prompt Performance Optimization</a></li>
<li><a href="promptperf-handson.html">Prompt Performance Optimization - Hands On</a></li>
<li><a href="promptenggtech.html">Prompt Engineering Techniques</a></li>
<li><a href="promptemp.html">Prompt Templates</a></li>
<li><a href="quiz3.html">Quiz</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-prompt-engineering"><a class="header" href="#what-is-prompt-engineering">What is Prompt Engineering?</a></h1>
<h2 id="introduction-to-prompt-engineering"><a class="header" href="#introduction-to-prompt-engineering">Introduction to Prompt Engineering</a></h2>
<p>So now let's talk about Prompt Engineering. What is Prompt Engineering exactly? Well, say we have a naive prompt, for example, "summarize what is AWS," and we submit this prompt to our LLM. This prompt is okay - we're going to get an answer from the LLM, but is it the answer we really want?</p>
<p>Prompting with this type of prompt will give little guidance and leaves a lot to the model's interpretation. So we can do Prompt Engineering, which means we're going to develop, design, and optimize these kinds of prompts to make sure that the foundation model's output will fit our needs.</p>
<h2 id="the-four-blocks-of-improved-prompting"><a class="header" href="#the-four-blocks-of-improved-prompting"><strong>The Four Blocks of Improved Prompting</strong></a></h2>
<p>To have an improved prompting technique, we have four blocks:</p>
<ol>
<li>
<p><strong>Instructions</strong> - What is the task for the model to do? We describe how the model should perform the task.</p>
</li>
<li>
<p><strong>Context</strong> - What is external information to guide the model?</p>
</li>
<li>
<p><strong>Input Data</strong> - What is the data for which we want a response?</p>
</li>
<li>
<p><strong>Output Indicator</strong> - What is the type or format of the output that we want?</p>
</li>
</ol>
<p>All these things together are going to give us a much better prompt and a much better answer.</p>
<h2 id="enhanced-prompt-example"><a class="header" href="#enhanced-prompt-example"><strong>Enhanced Prompt Example</strong></a></h2>
<p>Here is a concrete example where we are going to improve our naive prompt:
<img src="image-17.png" alt="alt text" /></p>
<h3 id="instructions"><a class="header" href="#instructions">Instructions</a></h3>
<p>Instead of just asking what AWS is, we want to write a concise summary that captures the main points of an article about learning AWS. We need to ensure that the summary is clear and informative, focusing on key services relevant to beginners, including details about general learning resources and career benefits associated with acquiring AWS skills.</p>
<h3 id="context"><a class="header" href="#context">Context</a></h3>
<p>I am teaching a beginner's course on AWS, so therefore, the model will respond in a way that can be understood by beginners.</p>
<h3 id="input-data"><a class="header" href="#input-data">Input Data</a></h3>
<p>Here is some input data about AWS - this is what I want the foundation model to summarize:</p>
<p>"Amazon Web Services (AWS) is a leading cloud platform providing a variety of services suitable for different business needs. Learning AWS involves getting familiar with essential services like EC2 for computing, S3 for storage, RDS for databases, Lambda for serverless computing, and Redshift for data warehousing. Beginners can start with free courses and basic tutorials available online. The platform also includes more complex services like Lambda for serverless computing and Redshift for data warehousing, which are suited for advanced users. The article emphasizes the value of understanding AWS for career advancement and the availability of numerous certifications to validate cloud skills."</p>
<h3 id="output-indicator"><a class="header" href="#output-indicator">Output Indicator</a></h3>
<p>I want the foundation model to provide a 2-3 sentence summary that will capture the essence of the article.</p>
<p>This is great because I'm very clear - I have provided very clear instructions, good context, input data, and an output indicator. Therefore, when I use it on my LLM, I will get the expected output, which are 2-3 sentences that summarize what AWS is based on this article from a beginner's context.</p>
<h2 id="negative-prompting-technique"><a class="header" href="#negative-prompting-technique"><strong>Negative Prompting Technique</strong></a></h2>
<p>Next, we have the technique called Negative Prompting. This is a technique where we explicitly instruct the model on what not to include or do in its response.</p>
<h3 id="benefits-of-negative-prompting"><a class="header" href="#benefits-of-negative-prompting">Benefits of Negative Prompting:</a></h3>
<p>‚Ä¢ <strong>Helps to avoid unwanted content</strong> - We specify explicitly what we don't want and therefore reduce the chances of irrelevant or inappropriate content</p>
<p>‚Ä¢ <strong>Maintains focus</strong> - We make sure that the prompt and the model will stay on the topic</p>
<p>‚Ä¢ <strong>Enhanced clarity</strong> - For example, we can say "Don't use complex terminology" or "Don't use detailed data," so we can make the output clearer</p>
<h2 id="enhanced-prompting-with-negative-prompting"><a class="header" href="#enhanced-prompting-with-negative-prompting"><strong>Enhanced Prompting with Negative Prompting</strong></a></h2>
<p>Let's look at the enhanced prompting from before, but now we're going to add negative prompting:</p>
<p><img src="image-18.png" alt="alt text" /></p>
<h3 id="instructions-enhanced"><a class="header" href="#instructions-enhanced">Instructions (Enhanced)</a></h3>
<p>The instructions are going to be exactly the same as before, but now I'm going to add: "Avoid discussing detailed technical configurations, specific AWS tutorials, or personal learning experiences."</p>
<h3 id="context-input-data"><a class="header" href="#context-input-data">Context, Input Data</a></h3>
<p>The context and input data will stay the same.</p>
<h3 id="output-indicator-enhanced"><a class="header" href="#output-indicator-enhanced">Output Indicator (Enhanced)</a></h3>
<p>For the output indicator, I'm going to say: "Provide a 2-3 sentence summary that captures the essence of the article. Do not include technical terms, in-depth data analysis, or speculation."</p>
<p>As you can see, by adding negative prompting, we are even more clear about what we want and what we don't want in an output from an LLM.</p>
<h2 id="conclusion"><a class="header" href="#conclusion"><strong>Conclusion</strong></a></h2>
<p>That's it for this lecture on Prompt Engineering. I suggest that you try a little bit on your own to see what you can and cannot get out of this technique.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-engineering---hands-on"><a class="header" href="#prompt-engineering---hands-on">Prompt Engineering - Hands On</a></h1>
<p>Okay, so let's practice how to do good prompting. We're going to go into <strong>chats</strong> and select a <strong>model</strong>. We're going to select <strong>Anthropic</strong>, and then we select <strong>Claude 3 Haiku</strong>.</p>
<p><img src="image-19.png" alt="alt text" /></p>
<h2 id="naive-prompt-example"><a class="header" href="#naive-prompt-example"><strong>Naive Prompt Example</strong></a></h2>
<p>Let's start with a basic example. We'll just write a prompt: <code>"write me a travel itinerary."</code></p>
<p><img src="IMG_9270.jpeg" alt="alt text" /></p>
<p>This prompt is very naive - it's not very detailed. Here the model just responds with a seven-day trip showing Rome, Florence, and Venice in Italy. This is an answer that is possible for us to deal with, but it's not the one I want because I was not very precise.</p>
<p><img src="IMG_9271.jpeg" alt="alt text" /></p>
<h2 id="using-the-prompting-framework"><a class="header" href="#using-the-prompting-framework"><strong>Using the Prompting Framework</strong></a></h2>
<p>Instead, we want to use the framework we had of giving instructions, giving context, giving input data, and then giving an output format. (as seen in previous lecture)</p>
<p>Under our code, under prompting, I've created prompting.txt, and we're going to use the first format - the instructions, the context, and the output.</p>
<p><img src="IMG_9272.jpeg" alt="alt text" /></p>
<h3 id="enhanced-prompt-structure"><a class="header" href="#enhanced-prompt-structure"><strong>Enhanced Prompt Structure</strong></a></h3>
<p>(See the example in the picture, below are explanations provided explaining how to do prompt engineering)
<strong>Instructions:</strong>
Please create a three-day itinerary for Paris, France. It should include visits to historical landmarks, art museums, and popular local restaurants. You want good balance, you want to have suggestions for breakfast, lunch, and dinner.</p>
<p><strong>Context:</strong>
We've never traveled to Paris before and we want to experience both the well-known and hidden gems. Of course, some people who have already been to Paris may want something different, so the <strong>context is very important</strong>.</p>
<p><strong>Input Data:</strong>
Right now is just a three-day trip to Paris. But we may want to add articles that we've read in the news, and this would be a good way to enhance the outcome of this prompt.</p>
<p><strong>Output Indicator:</strong>
We want the travel itinerary with specific times, locations, descriptions, and dining recommendations.</p>
<h3 id="results-of-enhanced-prompting"><a class="header" href="#results-of-enhanced-prompting"><strong>Results of Enhanced Prompting</strong></a></h3>
<p>This is quite a complete prompt. As you can see, now the model is telling us a lot (see the image below) of things about what to do on each specific day. This is quite nice because we are getting the recommendation we want for the exact prompt we cared about. It really shows you the difference of quality between a good and a bad prompt.</p>
<p><img src="IMG_9273.jpeg" alt="alt text" /></p>
<h2 id="adding-negative-prompting"><a class="header" href="#adding-negative-prompting"><strong>Adding Negative Prompting</strong></a></h2>
<p>Now, we also must include, if we want to improve it, negative prompting. Negative prompting is what do we not want to see? (see the example image below)
<img src="IMG_9274.jpeg" alt="alt text" /></p>
<h3 id="negative-prompting-example"><a class="header" href="#negative-prompting-example"><strong>Negative Prompting Example:</strong></a></h3>
<p>Here, for example:<br>
‚Ä¢ Do not include activities that are primarily for children or families<br>
‚Ä¢ Avoid overly touristy restaurants  <br>
‚Ä¢ Include anything that requires too much travel, except Versailles<br></p>
<p>Let's paste it and run it. Again, you can have a look at whether this output was better than the previous one or not based on the negative prompting.
<img src="IMG_9275.jpeg" alt="alt text" /></p>
<h2 id="creative-negative-prompting"><a class="header" href="#creative-negative-prompting"><strong>Creative Negative Prompting</strong></a></h2>
<p>We can do any kind of creative negative prompting. For example, we can say:<br>
‚Ä¢ Here's the instructions<br>
‚Ä¢ Do not recommend more than three activities per day<br></p>
<p>We run it, and again, with the negative prompting, now we're getting fewer activities per day. So it's a bit shorter day and maybe we'll have more time to do stuff in Paris.</p>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1"><strong>Conclusion</strong></a></h2>
<p>I cannot tell you if this is a good recommendation or not. I lived in Paris, but AI can be sometimes surprising. Anyway, if you would trust AI to organize your next travel, you know how to do it now and you know how to properly build a prompt for it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-performance-optimization"><a class="header" href="#prompt-performance-optimization">Prompt Performance Optimization</a></h1>
<h2 id="introduction-to-text-generation-process"><a class="header" href="#introduction-to-text-generation-process">Introduction to Text Generation Process</a></h2>
<p>So now let's talk about how we can improve the performance of our prompts in our model. First, let's step back and remember how text is being generated from an LLM.</p>
<p><img src="image-6.png" alt="alt text" /></p>
<p>For example, we have the sentence: "After the rain, the streets were..." and then we have the next word that will be computed by the Gen-AI Model. We can have wet, flooded, slippery, empty, muddy, clean, blocked, and all of these words have associated probabilities for how likely this is going to be the next picked word.</p>
<p>The Gen-AI Model will do some <strong>probability calculation</strong> and will select a <strong>word randomly</strong>, for example, "flooded"</p>
<p>This is something we've seen and I hope you remember it because now we're going to do a deep dive into that specific process and see how we can slightly influence it.</p>
<h2 id="understanding-the-core-concepts"><a class="header" href="#understanding-the-core-concepts">Understanding the Core Concepts</a></h2>
<p>Before diving in, let us review core concepts:</p>
<h3 id="temperature-vs-top-p-vs-top-k---the-key-differences"><a class="header" href="#temperature-vs-top-p-vs-top-k---the-key-differences"><strong>Temperature vs Top P vs Top K - The Key Differences</strong></a></h3>
<p>Think of it this way: when the AI is choosing the next word, it has a list of possible words with probabilities (like in your first image).</p>
<h4 id="temperature"><a class="header" href="#temperature"><strong>Temperature</strong></a></h4>
<ul>
<li><strong>What it does</strong>: Controls how "random" or "creative" the selection process is</li>
<li><strong>How it works</strong>:
<ul>
<li>Low temperature (0.2) = AI picks the most likely words more often (conservative)</li>
<li>High temperature (1.0) = AI is more willing to pick less likely words (creative/risky)</li>
</ul>
</li>
<li><strong>Think of it as</strong>: The "boldness" setting - how willing is the AI to take chances?</li>
</ul>
<h4 id="top-p"><a class="header" href="#top-p"><strong>Top P</strong></a></h4>
<ul>
<li><strong>What it does</strong>: Limits which words the AI can even consider, based on cumulative probability</li>
<li><strong>How it works</strong>:
<ul>
<li>Low P (0.25) = Only consider words that make up the top 25% of total probability</li>
<li>High P (0.99) = Consider almost all possible words</li>
</ul>
</li>
<li><strong>Think of it as</strong>: The "vocabulary filter" - what percentage of the total probability mass should we include?</li>
</ul>
<h4 id="top-k"><a class="header" href="#top-k"><strong>Top K</strong></a></h4>
<ul>
<li><strong>What it does</strong>: Limits which words the AI can consider, based on a fixed number</li>
<li><strong>How it works</strong>:
<ul>
<li>Low K (10) = Only look at the 10 most likely words</li>
<li>High K (500) = Look at the top 500 most likely words</li>
</ul>
</li>
<li><strong>Think of it as</strong>: The "shortlist size" - how many words should we put on the candidate list?</li>
</ul>
<h4 id="simple-example"><a class="header" href="#simple-example"><strong>Simple Example</strong></a></h4>
<p>If the AI is completing "The sky is..." and has 1000 possible next words:</p>
<ul>
<li><strong>Top K = 10</strong>: Only consider the 10 most likely words (blue, clear, dark, etc.)</li>
<li><strong>Top P = 0.25</strong>: Only consider words that together make up 25% of all probability (might be just 3-4 words)</li>
<li><strong>Temperature = 0.2</strong>: From whichever words made it through Top K/Top P, pick very conservatively (probably "blue")</li>
</ul>
<h2 id="prompt-performance-optimization-parameters"><a class="header" href="#prompt-performance-optimization-parameters"><strong>Prompt Performance Optimization Parameters</strong></a></h2>
<p>Let's go into the prompt performance optimization. This is a screenshot from Amazon Bedrock, and as you can see, we have a few knobs that we can change.
<img src="image-20.png" alt="alt text" /></p>
<h3 id="system-prompts"><a class="header" href="#system-prompts"><strong>System Prompts</strong></a></h3>
<p>We can specify how the model should behave and reply. In my example, I say "reply as if you are a teacher in the AWS Cloud Space." Of course, we set the tone for the answer, and this will really help the LLM to respond the way we want to.</p>
<h3 id="temperature-0-to-1"><a class="header" href="#temperature-0-to-1"><strong>Temperature (0 to 1)</strong></a></h3>
<p>This is a value you set from zero to one that defines the creativity of the model's outputs.</p>
<p>‚Ä¢ <strong>Low Temperature (e.g., 0.2)</strong> - The outputs are going to be more conservative, repetitive, and focused on the most likely response (the words with the highest probability)</p>
<p>‚Ä¢ <strong>High Temperature (e.g., 1.0)</strong> - The outputs are going to be more diverse, more creative, less predictable, and also maybe less coherent because it's going to select more words that would be less likely over time</p>
<p>It's for you to try and see what temperature works for you, but think at least, like if you have a high temperature, everything moves and so therefore you have more creativity.</p>
<h3 id="top-p-0-to-1"><a class="header" href="#top-p-0-to-1"><strong>Top P (0 to 1)</strong></a></h3>
<p>Top P is a value again, from zero to one.</p>
<p>‚Ä¢ <strong>Low P (e.g., 0.25)</strong> - In the list that we saw before about the next word that can be selected, we will only consider the 25% most likely words. Therefore, we'll have a more coherent response because we only select the words that really make sense.</p>
<p>‚Ä¢ <strong>High P (e.g., 0.99)</strong> - We're going to consider a very broad range of possible words, and therefore we have a long list to choose from, so possibly we're going to get a more creative and more diverse output.</p>
<p>As you can see, Temperature, Top P, and then of course, Top K and all the rest of these parameters can be used together.</p>
<h3 id="top-k-1"><a class="header" href="#top-k-1"><strong>Top K</strong></a></h3>
<p>Top K is the limit of the number of probable words. While Top P is considering the most likely words as a distribution, Top K is a number.<br><br></p>
<p>‚Ä¢ <strong>Low K (e.g., 10)</strong> - You're going to get the top 10 most probable words. You're going to get probably a more coherent response.<br><br></p>
<p>‚Ä¢ <strong>High K (e.g., 500)</strong> - You're going to consider the top 500 words. Therefore there's a chance if one of them is selected, that you get a more diverse and more creative answer.<br><br></p>
<h3 id="length"><a class="header" href="#length"><strong>Length</strong></a></h3>
<p>We define what is the maximum length of the answer. We tell the model to stop at some point.</p>
<h3 id="stop-sequences"><a class="header" href="#stop-sequences"><strong>Stop Sequences</strong></a></h3>
<p>What are some of the tokens that will signal the model to stop generating outputs? If the model has that token, then it stops.</p>
<h2 id="exam-preparation-note"><a class="header" href="#exam-preparation-note"><strong>Exam Preparation Note</strong></a></h2>
<blockquote>
<p>From an exam perspective, you need to remember the definition of all of these, what they mean for low and high values. So remember: <strong>Temperature</strong>, <strong>Top P</strong>, <strong>Top K</strong>, <strong>length</strong>, <strong>system prompts</strong>, and <strong>stop sequences</strong>.</p>
</blockquote>
<h2 id="prompt-latency"><a class="header" href="#prompt-latency"><strong>Prompt Latency</strong></a></h2>
<p>What about prompt latency? Well, latency means <em><strong>how fast the model is going to respond to your inputs</strong></em>.</p>
<h3 id="factors-that-impact-latency"><a class="header" href="#factors-that-impact-latency"><strong>Factors That Impact Latency:</strong></a></h3>
<p>‚Ä¢ <strong>Model size</strong> - How big or how small the model is<br><br></p>
<p>‚Ä¢ <strong>Model type</strong> - For example, Llama is going to show different performance than Claude<br><br></p>
<p>‚Ä¢ <strong>Number of tokens in the input</strong> - The more context you give in the context window, the slower it's going to be<br><br></p>
<p>‚Ä¢ <strong>Output size</strong> - The bigger the output, the slower as well it's going to be<br><br></p>
<h3 id="important-note-about-latency"><a class="header" href="#important-note-about-latency"><strong>Important Note About Latency</strong></a></h3>
<p>These are very important factors, but you should know as well that <strong>latency is NOT impacted by Top P, Top K, or the Temperature parameters</strong>. It's good for you to know because the exam may ask you some questions about it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-performance-optimization---hands-on"><a class="header" href="#prompt-performance-optimization---hands-on">Prompt Performance Optimization - Hands On</a></h1>
<p>Now that we are hands-on with prompt engineering, let‚Äôs practice using different configurations to see how we can influence the creativity of a model using Claude 3 Sonnet on AWS.</p>
<h3 id="initial-setup"><a class="header" href="#initial-setup"><strong>Initial Setup</strong></a></h3>
<ul>
<li>We select <strong>Claude 3 Sonnet</strong> from <strong>Anthropic</strong> as our model.
<img src="image-21.png" alt="alt text" /></li>
<li>The prompt we enter:
<code>"Please write a short story about a robot learning how to cook."</code></li>
<li>We define the story to be <strong>short</strong>.</li>
<li>The <strong>maximum length</strong> is set to <strong>600 tokens</strong> to ensure brevity.</li>
</ul>
<h3 id="running-with-conservative-settings"><a class="header" href="#running-with-conservative-settings"><strong>Running with Conservative Settings</strong></a></h3>
<p>We begin with <strong>low creativity settings</strong> by configuring:</p>
<ul>
<li><strong>Temperature</strong>: Low</li>
<li><strong>Top P</strong>: Low</li>
<li><strong>Top K</strong>: Low</li>
</ul>
<blockquote>
<p>These settings are known to generate more <strong>conservative</strong> and predictable outputs.</p>
</blockquote>
<p><img src="image-22.png" alt="alt text" /></p>
<p><strong>Result</strong>:</p>
<ul>
<li>The model outputs a story with a <strong>kitchen scene</strong>, a <strong>chef</strong>, and a robot.</li>
<li>While the output looks interesting at a glance, it reads as <strong>plain and potentially boring</strong>.</li>
</ul>
<h3 id="increasing-creativity"><a class="header" href="#increasing-creativity"><strong>Increasing Creativity</strong></a></h3>
<p>Now we modify the settings to boost the model‚Äôs creativity:</p>
<ul>
<li><strong>Temperature</strong>: Increased</li>
<li><strong>Top P</strong>: Set to maximum</li>
<li><strong>Top K</strong>: Set to <strong>500</strong></li>
</ul>
<p><img src="image-23.png" alt="alt text" /></p>
<blockquote>
<p>These changes allow the model to explore a <strong>wider range of vocabulary</strong> and <strong>creative paths</strong>.</p>
</blockquote>
<p><strong>New Prompt (same as before)</strong>:</p>
<ul>
<li><code>"Please write a short story about a robot learning how to cook."</code></li>
</ul>
<p><strong>Result</strong>:</p>
<ul>
<li>
<p>The output becomes <strong>much more creative</strong>.</p>
</li>
<li>
<p>Elements include:</p>
<ul>
<li><strong>Optical sensors</strong></li>
<li>A <strong>human instructor</strong></li>
<li>Cooking <strong>crepes</strong></li>
<li>The robot even tries <strong>eating</strong> the food</li>
</ul>
</li>
</ul>
<h3 id="comparison-and-summary"><a class="header" href="#comparison-and-summary"><strong>Comparison and Summary</strong></a></h3>
<ul>
<li>Both <strong>low-temperature</strong> and <strong>high-temperature</strong> prompt outputs will be saved in the code directory for comparison.</li>
<li>This exercise shows <strong>how different configurations affect the output</strong>.</li>
</ul>
<hr />
<h3 id="key-takeaways"><a class="header" href="#key-takeaways"><strong>Key Takeaways</strong></a></h3>
<ul>
<li><strong>Temperature</strong>: Controls the <strong>overall creativity</strong> of the model.</li>
<li><strong>Top P</strong>: Determines the <strong>percentile</strong> of word probabilities considered.</li>
<li><strong>Top K</strong>: Specifies <strong>how many words</strong> are considered for the next word prediction.</li>
</ul>
<blockquote>
<p>Hopefully, this demonstration helped you understand how model configurations influence outputs.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-engineering-techniques"><a class="header" href="#prompt-engineering-techniques">Prompt Engineering Techniques</a></h1>
<p>Coming Soon</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-templates"><a class="header" href="#prompt-templates">Prompt Templates</a></h1>
<p>Coming Soon</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quiz-on-prompt-engineering"><a class="header" href="#quiz-on-prompt-engineering">Quiz on Prompt Engineering</a></h1>
<p>Coming Soon</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="amazon-q"><a class="header" href="#amazon-q">Amazon Q</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai--ml--dl-concepts"><a class="header" href="#ai--ml--dl-concepts">AI &amp; ML &amp; DL Concepts</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managed-ai-services"><a class="header" href="#managed-ai-services">Managed AI Services</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sagemaker"><a class="header" href="#sagemaker">Sagemaker</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="challenges-and-responsibilites"><a class="header" href="#challenges-and-responsibilites">Challenges and Responsibilites</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="security-and-more"><a class="header" href="#security-and-more">Security and More</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="practice-test"><a class="header" href="#practice-test">Practice Test</a></h1>
<p>Coming soon ‚Äî stay tuned!</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
